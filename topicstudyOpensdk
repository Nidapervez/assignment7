
Swarm (OpenAI) ek experimental framework hai jo multi-agent AI systems ko lightweight aur ergonomic tareeqe se orchestrate karne ke liye banaya gaya tha. Isme do key concepts hain:

Agents: Independent AI units with specific tools & roles (e.g., billing, support).

Handoffs: Ek agent se doosre agent ko control dene ka mechanism, based on context.

Swarm ka goal tha ke multiple specialized agents mil kar complex tasks efficiently perform karein — jaise ek team.

Agents SDK (Swarm ka Evolution):
OpenAI ne Agents SDK launch kiya, jo Swarm ke principles par based hai lekin production-ready hai. Isme improved features hain for orchestrating multiple agents in a coordinated, testable, and scalable manner.

Anthropic Design Patterns (jo Agents SDK support karta hai):
Prompt Chaining: Task ko small steps mein break karke sequence mein solve karna.

Routing: Task ko best-suited agent tak forward karna.

Parallelization: Multiple subtasks ek saath solve karna.

Orchestrator-Workers: Ek main agent (orchestrator) subtasks ko delegate karta hai.

Evaluator-Optimizer: Performance monitor kar ke improvement suggest karna.

Summary:
Swarm = Experimental foundation.
Agents SDK = Uska advanced version for real-world use.
Dono ka maksad: Multi-agent AI systems ko smartly manage karna.
🔁 1. Swarm AI – Teamwork Jaisa AI
Socho tumhara ek call center hai jahan har agent kisi ek specific kaam mein expert hai:
🔍 OpenRouter: 50 Free LLMs ka Ek Interface
OpenRouter ek aisa platform hai jahan se tum 50 se zyada AI models (LLMs) free mein access kar sakti ho. Ye platform Google, OpenAI, Anthropic, Mistral, LLaMA jese providers ke models ko ek hi jagah per access karne ki suhulat deta hai.

Ye saare models mostly OpenAI Chat Completion API jese standard ko follow karte hain, isliye agar tumne pehle OpenAI ka SDK use kiya hai to sirf API key aur URL badal kar OpenRouter ke sath kaam kar sakti ho.

💡 Google Gemini 2.0 Flash vs OpenRouter Free Models
Feature	Google Gemini 2.0 Flash	OpenRouter Free Models
Requests Per Day (RPD)	1500	200
Requests Per Minute (RPM)	15 (Flash) / 30 (Lite)	20
Tokens Per Minute (TPM)	1,000,000	Depends
Compatible with OpenAI API?	✅	✅

👉 Toh development aur testing ke liye Google Gemini ka free tier zyada behtar hai kyunki usme zyada requests allow hoti hain. OpenRouter ko backup ke tor per use karo jab tumhe aur models test karne ho.

🧠 OpenRouter Kya Hai?
OpenRouter ek proxy hai – iska matlab ye khud model host nahi karta, balke tumhare requests ko third-party providers tak bhejta hai (jaise Together AI, AWS, Fireworks waghera). Isse tum easily 200+ models use kar sakti ho bina alag alag API keys manage kiye.

🛠️ Function Calling Support
OpenRouter function calling (yaani tool calling) support karta hai – matlab tum AI ko keh sakti ho ke external tools (jaise weather API) ka use kare user input ke basis per. Ye system OpenAI ke function calling jaise hi kaam karta hai.

🧪 Developer Friendly Features
Chatroom: Direct LLMs ke sath interact karne ke liye

Token aur Cost Monitoring

Streaming Support

OpenAI SDK Compatibility

Playground for testing

Prompt Logging (optional)

📊 Free Models ka Overview (March 2025)
OpenRouter ke paas 50 free models hain

Inmein se 6 models aise hain jinka context window 1 million tokens se zyada hai

Free models ka rate limit: 200 RPD aur 20 RPM

🔗 Useful Links:
🔹 OpenRouter Website

🔹 DeepSeek V3 Model (Free)

🔹 Google Gemini Chat API + OpenAI Compatibility

🔹 Function Calling Docs

🔹 Panaverse Code Example
Agent A: Sirf billing issues solve karta hai

Agent B: Sirf technical problems handle karta hai

Agent C: Sirf customer feedback leta hai

Ab koi customer aata hai aur kehta hai:

"Mera bill galat hai aur app kaam nahi kar rahi."

Toh ek agent sab kaam akela nahi karega — balki:

Pehle Agent A billing check karega

Phir Agent B technical issue solve karega

Phir Agent C feedback le lega

Yehi Swarm AI ka concept hai — multiple chhote, intelligent agents jo mil kar ek bada kaam efficiently karte hain.

🧠 2. Agents SDK – Swarm ka Professional Version
Swarm ek experimental concept tha. Jab OpenAI ne dekha ke ye kaam karta hai, to unhone uska powerful version banaya jiska naam hai:

👉 Agents SDK
Ye developers ke liye ek tool hai jisse wo multiple AI agents create kar sakte hain jo:

Ek dusre se baat karte hain

Apne-apne kaam independently karte hain

Coordination ke sath task complete karte hain

🤖 Real Example: Agents SDK in Action
Socho tum ek e-commerce site banati ho, aur tum chah rahi ho ek AI system jo:

Customer ke sawal ka jawab de (support agent)

Order history fetch kare (data agent)

Delivery track kare (shipment agent)

Agents SDK se tum ye 3 agents bana sakti ho — aur jab user kuch poochhe:

System understand karega ke kisko kaam dena hai

Relevant agent kaam karega

Final result combine ho kar user ko milega

🧩 Key Concepts (With Simple Analogies)
Concept	Asan Explanation
Agents	Jaise employees in a company — har agent ek role mein expert hota hai
Handoff	Jaise ek employee ka kaam complete hone ke baad wo file doosre employee ko deta hai
Prompt Chaining	Kaam ko chhoti chhoti steps mein todna (pehle name pucho, phir issue, phir solution)
Routing	Jaise receptionist decide kare ke kaunse department ko file bhejni hai
Parallelization	Multiple kaam ek saath chal rahe hoon (jaise ek agent bill dekh raha ho, doosra delivery)
Evaluator-Optimizer	Ek AI supervisor jo dekhta hai kiska kaam acha tha, aur kis agent ko improve karna hai

💡 Use Karne Ke Fayde
Task fast aur smartly complete hote hain

Har agent apne kaam mein expert hota hai

Bada problem, chhote pieces mein solve hota hai

Easy to scale — naye agents add karo, system smarter banega
🛠️ Installation Steps
Packages install karo:
Notebook mein ye line run karo:

python
Copy
Edit
!pip install -Uq openai-agents "openai-agents[litellm]"
Async ka support enable karo:
Notebook async function handle kar sake is liye ye likho:

python
Copy
Edit
import nest_asyncio
nest_asyncio.apply()
Google Colab mein API key save karo:

python
Copy
Edit
from google.colab import userdata
GEMINI_API_KEY = userdata.get("GEMINI_API_KEY")
📒 Notebook Ka Overview (03_Litellm_agent_sdk.ipynb)
Notebook mein ye steps hain:

openai-agents aur litellm install karna

nest_asyncio se async enable karna

Google Gemini ko LiteLLM ke zariye agent mein use karna

Ek function tool banana jo weather bataye

Agent se haiku style mein jawab lena

🧠 Important Code Example (Samjhay gaya)
python
Copy
Edit
from agents import Agent, Runner, function_tool
from agents.extensions.models.litellm_model import LitellmModel

MODEL = 'gemini/gemini-2.0-flash'

@function_tool
def get_weather(city: str) -> str:
    print(f"[debug] getting weather for {city}")
    return f"The weather in {city} is sunny."

agent = Agent(
    name="Assistant",
    instructions="You only respond in haikus.",
    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),
)

result = Runner.run_sync(agent, "What's the weather in Tokyo?")
print(result.final_output)
✅ Expected Output Example
Agar tum agent se pucho:

"What's the weather in Tokyo?"

To jawab ho sakta hai kuch is tarah:

arduino
Copy
Edit
Skies now partly clear,  
Seventy degrees in Tokyo,  
Gentle breeze abounds.
(Yaani poora haiku form mein!)

📌 Kaise Chalana Hai (Usage Guide)
Jupyter ya Colab mein 03_Litellm_agent_sdk.ipynb notebook kholo

Apna Gemini API key set karo

Saare cells ko ek ke baad ek run karo

"MODEL" aur user query change karke alag Gemini versions ya sawalat try karo

⚠️ Important Notes
get_weather() function filhaal fake data de raha hai. Production mein use replace kar do real API se jaise OpenWeatherMap.

Tracing off rakha gaya hai taake output clean ho. Debug ke liye tracing on bhi kar sakti ho.

API key ko kabhi bhi code mein hardcode mat karo – safe jagah store karo.


🔄 OpenRouter vs LiteLLM vs openai-agents SDK — Kya Faraq Hai?
🔸 1. OpenRouter:
Ye ek gateway (yaani rasta) hai jiske through tum kai LLM providers ko access kar sakti ho (jaise OpenAI, Google Gemini, Mistral, Claude, etc.) ek hi API ke zariye.

🔹 Use case: Jab tum chah rahi ho ke ek hi jaga se multiple models access karo (multi-model routing).

🔸 Example:

ts
Copy
Edit
model: "openrouter/google/gemini-pro"
🔸 2. LiteLLM:
Ye ek Python library hai jo tumhein multiple LLMs ko ek common interface se use karne ka tareeqa deti hai — lekin local Python environment mein.

🔹 Use case: Jab tum chah rahi ho ke Python code mein directly different models try karo — without worrying ke API ka format kya hai.

🔸 Example:

python
Copy
Edit
model = LitellmModel(model="gemini/gemini-2.0-flash", api_key=GEMINI_API_KEY)
🔸 3. openai-agents SDK:
Ye ek AI Agent banane ka framework hai jo tumhein kuch tools deta hai:

Agents create karne ke liye

Tools integrate karne ke liye (jaise get_weather)

Multiple model backends use karne ke liye, via extensions (jaise Litellm)

🔁 Toh ab sawal: "OpenRouter aur LiteLLM dono agent SDK mein use hotay hain?"
✅ Jee haan, Agent SDK in dono ko use kar sakta hai — bas extension change hoti hai:
👉 Agar tum:

from agents.extensions.models.litellm_model import LitellmModel
use kar rahi ho, toh tum LiteLLM ke through model access kar rahi ho.

👉 Aur agar tum:

from agents.extensions.models.openrouter_model import OpenrouterModel
use karti ho, toh tum OpenRouter ke through LLM use kar rahi ho.

🎯 Summary in 1 Line:
Tool	Kya Hai	Kab Use Hota Hai?
OpenRouter	Multi-model API Gateway	Jab tum web-based multi-model support chah rahi ho
LiteLLM	Local Python abstraction	Jab tum local Python code mein LLMs access karna chah rahi ho
openai-agents SDK	Agent banane ka framework	Iske andar tum OpenRouter ya LiteLLM dono ko backend ke tor pe use kar sakti ho

💡 Tum kya kar sakti ho?
Agar tum OpenRouter se Gemini access karna chah rahi ho, toh tum OpenrouterModel use karo.

Agar tum LiteLLM se Gemini access karna chah rahi ho, toh LitellmModel use karo.

Dono different tareeqe hain, end goal same hai — Gemini ya koi aur model run karwana agent ke through.









